# tryLock、lock和lockInterruptibly的区别

**synchronized和ReentrantLock的共同点如下**

- tryLock若有可用锁，则获取该锁并返回true，否则返回false，不会有延迟或等待；tryLock(long timeout, TimeUnit unit)可以增加时间限制，如果超过了指定的时间还没获得锁，则返回false。
-  lock若有可用锁，则获取该锁并返回true，否则会一直等待直到获取可用锁。◎
- 在锁中断时lockInterruptibly会抛出异常，lock不会。

**synchronized和ReentrantLock的不同点**

- ReentrantLock显式获取和释放锁；synchronized隐式获取和释放锁。为了避免程序出现异常而无法正常释放锁，**在使用ReentrantLock时必须在finally控制块中进行解锁操作**。
- ReentrantLock可响应中断、可轮回，为处理锁提供了更多的灵活性。
- ReentrantLock是API级别的，synchronized是JVM级别的。◎
- ReentrantLock可以定义公平锁。
- ReentrantLock通过Condition可以绑定多个条件。
- 二者的底层实现不一样：synchronized是同步阻塞，采用的是悲观并发策略；Lock是同步非阻塞，采用的是乐观并发策略。
- Lock是一个接口，而synchronized是Java中的关键字，synchronized是由内置的语言实现的。
-  我们通过Lock可以知道有没有成功获取锁，通过synchronized却无法做到。
-  Lock可以通过分别定义读写锁提高多个线程读操作的效率。



# Semaphore

Semaphore是一种基于计数的信号量，在定义信号量对象时可以设定一个阈值，基于该阈值，多个线程竞争获取许可信号，线程竞争到许可信号后开始执行具体的业务逻辑，业务逻辑在执行完成后释放该许可信号。在许可信号的竞争队列超过阈值后，新加入的申请许可信号的线程将被阻塞，直到有其他许可信号被释放。

```
public class SemaphoreDemo {

    public static int clientTotal = 5000;

    // 同时并发执行的线程数
    public static int threadTotal = 200;

    public static LongAdder count = new LongAdder();

    public static void main(String[] args) throws InterruptedException {
        ExecutorService executorService = Executors.newCachedThreadPool();
        // Semaphore 是 synchronized 的加强版，作用是控制线程的并发数量
        final Semaphore semaphore = new Semaphore(threadTotal);

        final CountDownLatch countDownLatch = new CountDownLatch(clientTotal);

        for (int i = 0; i < clientTotal; i++) {
            executorService.execute(() -> {
                try {
                    semaphore.acquire();
                    add();
                    semaphore.release();
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                countDownLatch.countDown();
            });
        }

        countDownLatch.await();
        executorService.shutdown();
        System.out.println("count = " + count);
    }

    private static void add() {
        count.increment();
        //count.getAndIncrement();
    }
}
```

**Semaphone.acquire方法默认和ReentrantLock. lockInterruptibly方法的效果一样，为可响应中断锁，也就是说在等待许可信号资源的过程中可以被Thread.interrupt方法中断而取消对许可信号的申请。**



# 公平锁与非公平锁

- 公平锁（Fair Lock）指在分配锁前检查是否有线程在排队等待获取该锁，优先将锁分配给排队时间最长的线程。
- 非公平锁（Nonfair Lock）指在分配锁时不考虑线程排队等待的情况，直接尝试获取锁，在获取不到锁时再排到队尾等待。



# 读写锁：ReadWriteLock

为了提高性能，Java提供了读写锁。读写锁分为读锁和写锁两种，多个读锁不互斥，读锁与写锁互斥。在读的地方使用读锁，在写的地方使用写锁，在没有写锁的情况下，读是无阻塞的。

```
public class SeafCache {

    private final Map<String, Object> cache = new HashMap<String, Object>();

    private final ReentrantReadWriteLock rwLock = new ReentrantReadWriteLock();
    // 读锁
    private final Lock readLock = rwLock.readLock();
    // 写锁
    private final Lock writeLock = rwLock.writeLock();

    public Object get(String key) {
        readLock.lock();
        try {
            return cache.get(key);
        } finally {
            readLock.unlock();
        }
    }

    public Object put(String key, Object value) {
        writeLock.lock();
        try {
            return cache.put(key, value);
        } finally {
            writeLock.unlock();
        }
    }
}
```



# 共享锁和独占锁

- 独占锁：也叫互斥锁，每次只允许一个线程持有该锁，ReentrantLock为独占锁的实现。
-  共享锁：允许多个线程同时获取该锁，并发访问共享资源。ReentrantReadWriteLock中的读锁为共享锁的实现。

ReentrantReadWriteLock的加锁和解锁操作最终都调用内部类Sync提供的方法。Sync对象通过继承AQS（Abstract Queued Synchronizer）进行实现。AQS的内部类Node定义了两个常量SHARED和EXCLUSIVE，分别标识AQS队列中等待线程的锁获取模式。

独占锁是一种悲观的加锁策略，同一时刻只允许一个读线程读取锁资源，限制了读操作的并发性；因为并发读线程并不会影响数据的一致性，因此共享锁采用了乐观的加锁策略，允许多个执行读操作的线程同时访问共享资源。



# 重量级锁和轻量级锁

重量级锁是基于操作系统的互斥量（Mutex Lock）而实现的锁，**会导致进程在用户态与内核态之间切换，相对开销较大**。

synchronized在内部基于监视器锁（Monitor）实现，监视器锁基于底层的操作系统的MutexLock实现，因此synchronized属于重量级锁。重量级锁需要在用户态和核心态之间做转换，所以synchronized的运行效率不高。

JDK在1.6版本以后，为了减少获取锁和释放锁所带来的性能消耗及提高性能，引入了轻量级锁和偏向锁。轻量级锁是相对于重量级锁而言的。轻量级锁的核心设计是在没有多线程竞争的前提下，减少重量级锁的使用以提高系统性能。

**轻量级锁适用于线程交替执行同步代码块的情况（即互斥操作），如果同一时刻有多个线程访问同一个锁，则将会导致轻量级锁膨胀为重量级锁。**



# 偏向锁

偏向锁用于在某个线程获取某个锁之后，消除这个线程锁重入的开销，看起来似乎是这个线程得到了该锁的偏向（偏袒）。

偏向锁的主要目的是在同一个线程多次获取某个锁的情况下尽量减少轻量级锁的执行路径，因为轻量级锁的获取及释放需要多次CAS（Compare and Swap）原子操作，而偏向锁只需要在切换ThreadID时执行一次CAS原子操作，因此可以提高锁的运行效率。



# 分段锁

分段锁并非一种实际的锁，而是一种思想，用于将数据分段并在每个分段上都单独加锁，把锁进一步细粒度化，以提高并发效率。ConcurrentHashMap在内部就是使用分段锁实现的。



# 同步锁与死锁

在有多个线程同时被阻塞时，它们之间若相互等待对方释放锁资源，就会出现死锁。为了避免出现死锁，**可以为锁操作添加超时时间，在线程持有锁超时后自动释放该锁。**



#  如何进行锁优化

1．减少锁持有的时间减少锁持有的时间指只在有线程安全要求的程序上加锁来尽量减少同步代码块对锁的持有时间。

2．减小锁粒度减小锁粒度指将单个耗时较多的锁操作拆分为多个耗时较少的锁操作来增加锁的并行度，减少同一个锁上的竞争。在减少锁的竞争后，偏向锁、轻量级锁的使用率才会提高。减小锁粒度最典型的案例就是ConcurrentHashMap中的分段锁。

3．锁分离锁分离指根据不同的应用场景将锁的功能进行分离，以应对不同的变化，最常见的锁分离思想就是读写锁（ReadWriteLock），它根据锁的功能将锁分离成读锁和写锁，这样读读不互斥，读写互斥，写写互斥，既保证了线程的安全性，又提高了性能。操作分离思想可以进一步延伸为只要操作互不影响，就可以进一步拆分，比如LinkedBlockingQueue从头部取出数据，并从尾部加入数据。

4．锁粗化锁粗化指为了保障性能，会要求尽可能将锁的操作细化以减少线程持有锁的时间，但是如果锁分得太细，将会导致系统频繁获取锁和释放锁，反而影响性能的提升。在这种情况下，建议将关联性强的锁操作集中起来处理，以提高系统整体的效率。

5．锁消除在开发中经常会出现在不需要使用锁的情况下误用了锁操作而引起性能下降，这多数是因为程序编码不规范引起的。这时，我们需要检查并消除这些不必要的锁来提高系统的性能。



# Java阻塞队列

阻塞队列和一般队列的不同之处在于阻塞队列是“阻塞”的，这里的阻塞指的是操作队列的线程的一种状态。在阻塞队列中，线程阻塞有如下两种情况。

- 消费者阻塞：在队列为空时，消费者端的线程都会被自动阻塞（挂起），直到有数据放入队列，消费者线程会被自动唤醒并消费数据

- 生产者阻塞：在队列已满且没有可用空间时，生产者端的线程都会被自动阻塞（挂起），直到队列中有空的位置腾出，线程会被自动唤醒并生产数据

**ArrayBlockingQueue**

ArrayBlockingQueue是基于数组实现的有界阻塞队列。ArrayBlockingQueue队列按照先进先出原则对元素进行排序，在默认情况下不保证元素操作的公平性。

**LinkedBlockingQueue**

LinkedBlockingQueue是基于链表实现的阻塞队列，同ArrayListBlockingQueue类似，此队列按照先进先出原则对元素进行排序；LinkedBlockingQueue对生产者端和消费者端分别采用了两个独立的锁来控制数据同步，我们可以将队列头部的锁理解为写锁，将队列尾部的锁理解为读锁，因此生产者和消费者可以基于各自独立的锁并行地操作队列中的数据，队列的并发性能较高。

**PriorityBlockingQueue**

PriorityBlockingQueue是一个支持优先级的无界队列。元素在默认情况下采用自然顺序升序排列。



# CountDownLatch

CountDownLatch类位于java.util.concurrent包下，是一个同步工具类，允许一个或多个线程一直等待其他线程的操作执行完后再执行相关操作。

CountDownLatch基于线程计数器来实现并发访问控制，主要用于主线程等待其他子线程都执行完毕后执行相关操作。



# CyclicBarrier

CyclicBarrier（循环屏障）是一个同步工具，可以实现让一组线程等待至某个状态之后再全部同时执行。

CyclicBarrier的运行状态叫作Barrier状态，在调用await方法后，线程就处于Barrier状态。

- public int await()：挂起当前线程直到所有线程都为Barrier状态再同时执行后续的任务。
- public int await(long timeout, TimeUnit unit)：设置一个超时时间，在超时时间过后，如果还有线程未达到Barrier状态，则不再等待，让达到Barrier状态的线程继续执行后续的任务。

```
public class CyclicBarrierDemo {

    public static void main(String[] args) {
        int n = 4;
        CyclicBarrier cyclicBarrier = new CyclicBarrier(n);
        for (int i = 0; i < n; i++) {
            new BusinessThread(cyclicBarrier).start();
        }
    }

    // 业务线程
    static class  BusinessThread extends Thread {
        private CyclicBarrier cyclicBarrier;

        public BusinessThread(CyclicBarrier cyclicBarrier) {
            this.cyclicBarrier = cyclicBarrier;
        }

        @Override
        public void run() {
            try {
                Thread.sleep(1000); // 执行业务逻辑
                System.out.println("first task complate!!!!");
                // 业务线程执行完成，等待其他线程准备工作完成
                cyclicBarrier.await();
            } catch (InterruptedException e) {
                e.printStackTrace();
            } catch (BrokenBarrierException e) {
                e.printStackTrace();
            }
            System.out.println("所有都执行完成 开始执行下一任务");
        }
    }
}

```



# CountDownLatch、CyclicBarrier、Semaphore的区别如下

- CountDownLatch和CyclicBarrier都用于实现多线程之间的相互等待，但二者的关注点不同。CountDownLatch主要用于主线程等待其他子线程任务均执行完毕后再执行接下来的业务逻辑单元，而CyclicBarrier主要用于一组线程互相等待大家都达到某个状态后，再同时执行接下来的业务逻辑单元。此外，CountDownLatch是不可以重用的，而CyclicBarrier是可以重用的。
-  Semaphore和Java中的锁功能类似，主要用于控制资源的并发访问。



# volatile关键字的作用

稍弱的同步机制，即volatile变量。volatile也用于确保将变量的更新操作通知到其他线程。

volatile变量具备两种特性：

- 一种是保证该变量对所有线程可见，在一个线程修改了变量的值后，新的值对于其他线程是可以立即获取的；
- 一种是volatile禁止指令重排，即volatile变量不会被缓存在寄存器中或者对其他处理器不可见的地方，因此在读取volatile类型的变量时总会返回最新写入的值。

**访问volatile变量时不会执行加锁操作，也就不会执行线程阻塞**，因此volatile变量是一种比synchronized关键字更轻量级的同步机制。volatile主要适用于一个变量被多个线程共享，多个线程均可针对这个变量执行赋值或者读取的操作。

volatile关键字可以**严格保障变量的单次读、写操作的原子性**，但并不能保证像i++这种操作的原子性，因为i++在本质上是读、写两次操作。

必须同时满足下面两个条件才能保证并发环境的线程安全：

- **对变量的写操作不依赖于当前值（比如i++），或者说是单纯的变量赋值（boolean flag= true）。**

- 该变量没有被包含在具有其他变量的不变式中，也就是说在不同的volatile变量之间不能互相依赖，只有在状态真正独立于程序内的其他内容时才能使用volatile。

# 多线程如何共享数据

在Java中进行多线程通信主要是通过共享内存实现的，共享内存主要有三个关注点：可见性、有序性、原子性。Java内存模型（JVM）解决了可见性和有序性的问题，而锁解决了原子性的问题。

**将数据抽象成一个类，并将对这个数据的操作封装在类的方法中**

 **将Runnable对象作为一个类的内部类，将共享数据作为这个类的成员变量**



# ConcurrentHashMap并发

## 减小锁粒度

减小锁粒度指通过缩小锁定对象的范围来减少锁冲突的可能性，最终提高系统的并发能力。

ConcurrentHashMap是线程安全的Map，对于HashMap而言，最重要的方法是get和set方法，如果为了线程安全对整个HashMap加锁，则可以得到线程安全的对象，但是加锁粒度太大，意味着同时只能有一个线程操作HashMap，在效率上就会大打折扣；而ConcurrentHashMap在内部使用多个Segment，在操作数据时会给每个Segment都加锁，这样就通过减小锁粒度提高了并发度。

## ConcurrentHashMap的实现

ConcurrentHashMap在内部细分为若干个小的HashMap，叫作数据段（Segment）。在默认情况下，一个ConcurrentHashMap被细分为**16个数据段**，对每个数据段的数据都单独进行加锁操作。**Segment的个数为锁的并发度**。

**ConcurrentHashMap是由Segment数组和HashEntry数组组成的。Segment继承了可重入锁（ReentrantLock），它在ConcurrentHashMap里扮演锁的角色。HashEntry则用于存储键值对数据。**

在每一个ConcurrentHashMap里都包含一个Segment数组，Segment的结构和HashMap类似，是数组和链表结构。在每个Segment里都包含一个HashEntry数组，每个HashEntry都是一个链表结构的数据，每个Segment都守护一个HashEntry数组里的元素，在对HashEntry数组的数据进行修改时，必须首先获得它对应的Segment锁。



# Java中的线程调度

1 抢占式调度  Java线程调度的实现：抢占式

抢占式调度指每个线程都以抢占的方式获取CPU资源并快速执行，在执行完毕后立刻释放CPU资源，具体哪些线程能抢占到CPU资源由操作系统控制，**在抢占式调度模式下，每个线程对CPU资源的申请地位是相等，从概率上讲每个线程都有机会获得同样的CPU执行时间片并发执行**。抢占式调度**适用于多线程并发执行的情况**，在这种机制下一个线程的堵塞不会导致整个进程性能下降。

Java采用抢占式调度的方式实现内部的线程调度，J**ava会为每个线程都按照优先级高低分配不同的CPU时间片，且优先级高的线程优先执行**。**优先级低的线程只是获取CPU时间片的优先级被降低，但不会永久分配不到CPU时间片**。Java的线程调度在保障效率的前提下尽可能保障线程调度的公平性。

2 协同式调度

协同式调度指某一个线程在执行完后主动通知操作系统将CPU资源切换到另一个线程上执行。**线程对CPU的持有时间由线程自身控制，线程切换更加透明，更适合多个线程交替执行某些任务的情况。**

协同式调度有一个缺点：如果其中一个线程因为外部原因（可能是磁盘I/O阻塞、网络I/O阻塞、请求数据库等待）运行阻塞，那么可能导致整个系统阻塞甚至崩溃。



**线程让出CPU的情况如下：**

- 当前运行的线程主动放弃CPU，例如运行中的线程调用yield()放弃CPU的使用权。◎
- 当前运行的线程进入阻塞状态，例如调用文件读取I/O操作、锁等待、Socket等待。◎
- 当前线程运行结束，即运行完run()里面的任务。



# CAS

CAS（Compare And Swap）指比较并交换。CAS算法CAS(V, E, N)包含3个参数**，V表示要更新的变量，E表示预期的值，N表示新值**。在且仅在V值等于 E值时，才会将V值设为 N，如果 V值和 E值不同，则说明已经有其他线程做了更新，当前线程什么都不做。最后，CAS返回当前V的真实值。

**CAS的特性：乐观锁**

CAS操作**采用了乐观锁的思想**，总是认为自己可以成功完成操作。在有多个线程同时使用CAS操作一个变量时，只有一个会胜出并成功更新，其余均会失败。失败的线程不会被挂起，仅被告知失败，并且允许再次尝试，当然，也允许失败的线程放弃操作。基于这样的原理**，CAS操作即使没有锁，也可以发现其他线程对当前线程的干扰，并进行恰当的处理**。



**CAS自旋等待**

其内部便是基于CAS算法实现的，即在某个线程进入方法中执行其中的指令时，不会被其他线程打断；而别的线程就像自旋锁一样，一直等到该方法执行完成才由JVM从等待的队列中选择另一个线程进入。

相对于synchronized阻塞算法，CAS是非阻塞算法的一种常见实现。由于CPU的切换比CPU指令集的操作更加耗时，所以CAS的自旋操作在性能上有了很大的提升。



# 什么是AQS

AQS（Abstract Queued Synchronizer）是一个抽象的队列同步器，通**过维护一个共享资源状态（Volatile Int State）和一个先进先出（FIFO）的线程等待队列来实现一个多线程访问共享资源的同步框架**。

AQS为每个共享资源都设置一个共享资源锁，线程在需要访问共享资源时首先需要获取共享资源锁，如果获取到了共享资源锁，便可以在当前线程中使用该共享资源，如果获取不到，则将该线程放入线程等待队列，等待下一次资源调度，具体的流程如图3-14所示。许多同步类的实现都依赖于AQS，例如常用的ReentrantLock、Semaphore和CountDownLatch。

**AQS共享资源的方式：独占式和共享式**

独占式：只有一个线程能执行，具体的Java实现有ReentrantLock。

共享式：多个线程可同时执行，具体的Java实现有Semaphore和CountDownLatch。

同步器的实现是AQS的核心内存。ReentrantLock对AQS的独占方式实现为：**ReentrantLock中的state初始值为0时表示无锁状态。在线程执行tryAcquire()获取该锁后ReentrantLock中的state+1，这时该线程独占ReentrantLock锁，其他线程在通过tryAcquire()获取锁时均会失败，直到该线程释放锁后state再次为0**，其他线程才有机会获取该锁。该线程在释放锁之前可以重复获取此锁，**每获取一次便会执行一次state+1，因此ReentrantLock也属于可重入锁**。但获取多少次锁就要释放多少次锁，这样才能保证state最终为0。如果获取锁的次数多于释放锁的次数，则会出现该线程一直持有该锁的情况；如果获取锁的次数少于释放锁的次数，则运行中的程序会报锁异常。

CountDownLatch对AQS的共享方式实现为：CountDownLatch将任务分为N个子线程去执行，**将state也初始化为N, N与线程的个数一致，N个子线程是并行执行的，每个子线程都在执行完成后countDown()一次，state会执行CAS操作并减1**。在所有子线程都执行完成（state=0）时会unpark()主线程，然后主线程会从await()返回，继续执行后续的动作。